{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ensemble Learning is a technique that combines predictions from multiple base learners to produce improved results and reduce the generalization error. More the diversification between base learners, better will be the performance and stablity of the combined model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![ensemble](images/ensemblelearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Mathematically, for a machine learning model the error can be written as the following.\n",
    "\n",
    "Err(x)=(Bias)^2 + Variance + Irreducible Error\n",
    "\n",
    "Error due to Bias: Bias can be defined as how far off the predictions are from the actual values. A model is said to be underfitting if it has high bias. Meaning, the complexity of the model is low compared to the data.\n",
    "\n",
    "Error due to Variance: Variance is how much the predictions for a given point vary between different realizations of the model. If a small change in the model changes a particular prediction significantly,  because of the high complexity the model is likely to overfit the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Bias and Variance](images/biasvariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "We will take [Loan Prediction](https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/) problem to understand ensembling learning practically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEED = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data preprocessing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_preprocessing = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Loan_Prediction_data/train_u6lujuX_CVtuZ9i.csv');data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Gender  Married  Education  Self_Employed  ApplicantIncome  \\\n",
       "0  LP001002       1        0          1              0             5849   \n",
       "1  LP001003       1        1          1              0             4583   \n",
       "2  LP001005       1        1          1              1             3000   \n",
       "3  LP001006       1        1          0              0             2583   \n",
       "4  LP001008       1        0          1              0             6000   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                0.0  146.412162             360.0             1.0   \n",
       "1             1508.0  128.000000             360.0             1.0   \n",
       "2                0.0   66.000000             360.0             1.0   \n",
       "3             2358.0  120.000000             360.0             1.0   \n",
       "4                0.0  141.000000             360.0             1.0   \n",
       "\n",
       "   Loan_Status  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = data_preprocessing.preprocess(data);preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (564, 9)\n",
      "Test shape: (50, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, id_train, id_test = data_preprocessing.split_data(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classifier = model(X_train, y_train, X_test, id_train, id_test)\n",
    "lr_preds, lr_probs = classifier.fit_predict(LogisticRegression(C=0.2, random_state=SEED))\n",
    "dt_preds, dt_probs = classifier.fit_predict(DecisionTreeClassifier(max_depth=5, random_state=SEED))\n",
    "knn_preds, knn_probs = classifier.fit_predict(KNeighborsClassifier(n_neighbors=25))\n",
    "rf_preds, rf_probs = classifier.fit_predict(RandomForestClassifier(max_depth=2, random_state=SEED))\n",
    "xgb_preds, xgb_probs = classifier.fit_predict(XGBClassifier(max_depth=7, seed=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame({'True Lables': y_test.values, 'LR Preds': lr_preds, \n",
    "                         'DT Preds': dt_preds, 'KNN Preds': knn_preds,\n",
    "                         'RF Preds': rf_preds, 'XGB Preds': xgb_preds})\n",
    "\n",
    "probs_df = pd.DataFrame({'True Lables': y_test.values, 'LR Probs': lr_probs, \n",
    "                         'DT Probs': dt_probs, 'KNN Probs': knn_probs,\n",
    "                         'RF Probs': rf_probs, 'XGB Probs': xgb_probs})\n",
    "cols_preds = ['True Lables', 'LR Preds', 'DT Preds', 'KNN Preds', 'RF Preds', 'XGB Preds']\n",
    "cols_probs = [x.replace('Preds', 'Probs') if 'Preds' else x in x for x in cols_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ensembling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Voting](images/Voting_Cropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.1: Hard Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hard voting is used to improve the preformance of metrics such as accuracy, f1 etc., which are based on the actual predicitions. Voting predictions are obtained by taking the direct majority voting on the predictions from different models. Often best results are obtained when merging decorrelated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LR 0.74\n",
      "Accuracy DT 0.7\n",
      "Accuracy KNN 0.62\n",
      "Accuracy RF 0.74\n",
      "Accuracy XGB 0.7\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy LR {}'.format(accuracy_score(y_test.values, lr_preds)))\n",
    "print('Accuracy DT {}'.format(accuracy_score(y_test.values, dt_preds)))\n",
    "print('Accuracy KNN {}'.format(accuracy_score(y_test.values, knn_preds)))\n",
    "print('Accuracy RF {}'.format(accuracy_score(y_test.values, rf_preds)))\n",
    "print('Accuracy XGB {}'.format(accuracy_score(y_test.values, xgb_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy VOTING 0.76\n"
     ]
    }
   ],
   "source": [
    "voting_preds = preds_df[cols_preds].apply(lambda x: mode(x)[0][0], axis=1).values\n",
    "preds_df['Voting Preds'] = voting_preds\n",
    "\n",
    "print('Accuracy VOTING {}'.format(accuracy_score(y_test.values, voting_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Every algorithm treats the data differently and hence merging machine learning models generally performs better than individual model allowing more flexibility in handling Bias-Variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Ensemble Learning.xlsx')\n",
    "preds_df[cols_preds+['Voting Preds']].to_excel(writer,'Predictions')\n",
    "probs_df[cols_probs].to_excel(writer,'Probabilities')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.2: Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Soft voting predicts the class label based on the maximum value of the average of the predicted probabilities.\n",
    "Equal weights(Simple average) or unequal weights(Weighted average) can be assigned to each model predictions based on the individual performance of the models to improve the results. Soft voting works to improve the performance on metrics which are not specific to the order of probabilities rather depends on how close are the predicted probabilities are to the labels, for example, Logloss. Let's perform these tasks in excel for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2. Rank ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nature of predicted probabilities from different algorithms may or may not be the same, meaning the statistics of the probabilities may differ from each other depending on whether the algorithms are either underfitting or overfitting. Hence, soft voting may not be the right approach for ensembling. Rank ensembling, ranks the probabilities which then can be used for simple average or weighted average followed by scaling. Unlike Logloss, metrics like AUC are computed based on the order of probabilities. So, Rank average is the appropriate ensembling technique for optimizing AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC LR 0.8106617647058824\n",
      "AUC DT 0.6332720588235293\n",
      "AUC KNN 0.400735294117647\n",
      "AUC RF 0.7141544117647058\n",
      "AUC XGB 0.7849264705882353\n"
     ]
    }
   ],
   "source": [
    "print('AUC LR {}'.format(roc_auc_score(y_test.values, lr_probs)))\n",
    "print('AUC DT {}'.format(roc_auc_score(y_test.values, dt_probs)))\n",
    "print('AUC KNN {}'.format(roc_auc_score(y_test.values, knn_probs)))\n",
    "print('AUC RF {}'.format(roc_auc_score(y_test.values, rf_probs)))\n",
    "print('AUC XGB {}'.format(roc_auc_score(y_test.values, xgb_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "probs_df['LR_rank'] = rankdata(probs_df['LR Probs'])\n",
    "probs_df['DT_rank'] = rankdata(probs_df['DT Probs'])\n",
    "probs_df['KNN_rank'] = rankdata(probs_df['KNN Probs'])\n",
    "probs_df['RF_rank'] = rankdata(probs_df['RF Probs'])\n",
    "probs_df['XGB_rank'] = rankdata(probs_df['XGB Probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Rank Average 0.8143382352941176\n"
     ]
    }
   ],
   "source": [
    "probs_df['Final_rank'] = (probs_df['LR_rank']* 0.5 +\n",
    "                          probs_df['DT_rank']* 0.025 +\n",
    "                          probs_df['KNN_rank']* 0.025 +\n",
    "                          probs_df['RF_rank']* 0.1 +\n",
    "                          probs_df['XGB_rank']* 0.35)\n",
    "print('AUC Rank Average {}'.format(roc_auc_score(y_test.values, probs_df['Final_rank'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### There are numerous other ways to approach ensembling. Hard voting and soft voting are the two simplest techniques to perform ensembling. Bagging and boosting are two other approaches that are used to build machine learning algorithms with the primary idea of the voting methods discussed above with few modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Combining multiple similar or dissimilar algorithms each utilising randomly choosen subset of complete data for training is called bagging. Bagging is less prone to overfitting. Random forest is an example for bagging technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/BaggingCropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Boosting is a similar but more powerful appraoch than bagging. Except that boosting builds sequentially to optimize loss for every model by assigning weights on the data samples choosen. As the loss is optimized here, the complexity increases and is prone to overfitting but reduces bias. XGBoost, Lightgbm and recently released Catboost are all boosting algorithms. Boosting algorithms generally outperforms any other algorithms and hence the most used algorithm in competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/BoostingCropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5. Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Create a holdout of 10% of the train set\n",
    "2. Fit a model on the train set without the holdout\n",
    "3. Predict the untouched holdout with the trained first model\n",
    "4. Fit a logistic regression model on the generated probabilities and hold out labels to obtain the optimal weights for each model.\n",
    "5. Retrain the model on complete training data and use the obtained optimal weights for soft voting on test predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Blending is prone to overfitting as it majorly depends on the difference in dynamics of the hold-out set and future test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "build, holdout, y_build, y_holdout = train_test_split(X_train, y_train, test_size=0.1, random_state=SEED, stratify=y_train)\n",
    "cols_for_blending = np.setdiff1d(build.columns.values, ['Loan_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blending_classifier = model(build[cols_for_blending], y_build, holdout[cols_for_blending], _, _)\n",
    "lr_blending_preds, lr_blending_probs = blending_classifier.fit_predict(LogisticRegression(random_state=SEED))\n",
    "dt_blending_preds, dt_blending_probs = blending_classifier.fit_predict(DecisionTreeClassifier(random_state=SEED))\n",
    "knn_blending_preds, knn_blending_probs = blending_classifier.fit_predict(KNeighborsClassifier())\n",
    "rf_blending_preds, rf_blending_probs = blending_classifier.fit_predict(RandomForestClassifier(random_state=SEED))\n",
    "xgb_blending_preds, xgb_blending_probs = blending_classifier.fit_predict(XGBClassifier(seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blender Logloss: -0.5646234625202811\n"
     ]
    }
   ],
   "source": [
    "blender = LogisticRegression(C=0.7)\n",
    "\n",
    "train_blending = np.vstack((lr_blending_probs, dt_blending_probs, knn_blending_probs, rf_blending_probs, xgb_blending_probs)).T\n",
    "\n",
    "res = cross_val_score(blender, train_blending, y_holdout, cv=5, scoring='neg_log_loss')\n",
    "print('Blender Logloss: {}'.format(np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_blending = blender.fit(train_blending, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights = model_blending.coef_[0]\n",
    "weights = weights/weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blending_probs = (np.vstack((lr_probs, dt_probs, knn_probs, rf_probs, xgb_probs)).T*weights).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.vstack((lr_preds, dt_preds, knn_preds, rf_preds, xgb_preds)).T\n",
    "max_prob_index = np.argmax((np.vstack((lr_probs, dt_probs, knn_probs, rf_probs, xgb_probs)).T*weights), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blending_preds = [all_preds[i,j] for i,j in enumerate(max_prob_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "blending_df = pd.DataFrame({'True Labels': y_test, 'Blending Preds': blending_preds, 'Blending Probs': blending_probs})\n",
    "blending_df[['True Labels', 'Blending Preds', 'Blending Probs']].to_excel(writer, 'Blending Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Split the train set in k folds\n",
    "2. Fit a model on k-1 folds and predict the kth fold and the test set\n",
    "3. Repeat 2. to predict each fold\n",
    "4. We now have the (out-of-folds) prediction of the k folds and the average of all test predictions\n",
    "5. Use train and test out of folds predictions to fit a second level model with cross validation\n",
    "6. Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Out of fold predictions are used to avoid overfitting on the train data.\n",
    "\n",
    "stacking of more diversified models builds robustness and generalizes well on the test data. Hence, sometimes it is also known as stacked generalization.\n",
    "\n",
    "Either Linear models or Non-linear models can be used as the meta learners for stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_train_oof, lr_test_oof = classifier.get_oof(LogisticRegression(random_state=0), 'LogReg')\n",
    "dt_train_oof, dt_test_oof = classifier.get_oof(DecisionTreeClassifier(random_state=0), 'DT')\n",
    "knn_train_oof, knn_test_oof = classifier.get_oof(KNeighborsClassifier(), 'KNN')\n",
    "rf_train_oof, rf_test_oof = classifier.get_oof(RandomForestClassifier(random_state=0), 'RF')\n",
    "xgb_train_oof, xgb_test_oof = classifier.get_oof(XGBClassifier(seed=0), 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_oof = (lr_train_oof.merge(dt_train_oof, on='Loan_ID', how='left')\n",
    "                         .merge(knn_train_oof, on='Loan_ID', how='left')\n",
    "                         .merge(rf_train_oof, on='Loan_ID', how='left')\n",
    "                         .merge(xgb_train_oof, on='Loan_ID', how='left'))\n",
    "\n",
    "test_oof = (lr_test_oof.merge(dt_test_oof, on='Loan_ID', how='left')\n",
    "                         .merge(knn_test_oof, on='Loan_ID', how='left')\n",
    "                         .merge(rf_test_oof, on='Loan_ID', how='left')\n",
    "                         .merge(xgb_test_oof, on='Loan_ID', how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train['Loan_ID'] = id_train\n",
    "X_test['Loan_ID'] = id_test\n",
    "final_train = train_oof.merge(X_train, on='Loan_ID', how='left')\n",
    "final_test = test_oof.merge(X_test, on='Loan_ID', how='left')\n",
    "cols_for_model = np.setdiff1d(final_train.columns.values, ['Loan_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ApplicantIncome', 'CoapplicantIncome', 'Credit_History',\n",
       "       'DT_Prediction', 'Education', 'Gender', 'KNN_Prediction',\n",
       "       'LoanAmount', 'Loan_Amount_Term', 'LogReg_Prediction', 'Married',\n",
       "       'RF_Prediction', 'Self_Employed', 'XGB_Prediction'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stacker = LGBMClassifier(n_estimators=1200, max_bin=255, boosting_type='gbdt', colsample_bytree=0.7, seed=SEED,\n",
    "                         learning_rate=0.05, subsample=0.9, min_child_samples=200, num_leaves=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker Logloss: -0.5739773875959233\n"
     ]
    }
   ],
   "source": [
    "res = cross_val_score(stacker, final_train[cols_for_model], classifier.y, cv=5, scoring='neg_log_loss')\n",
    "print('Stacker Logloss: {}'.format(np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_second_level = stacker.fit(final_train[cols_for_model], classifier.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stacking_probs = clf_second_level.predict_proba(final_test[cols_for_model])[:, 1]\n",
    "stacking_preds = clf_second_level.predict(final_test[cols_for_model])\n",
    "stacking_df = pd.DataFrame({'True Labels': y_test, 'Stacking Preds': stacking_preds, 'Stacking Probs': stacking_probs})\n",
    "stacking_df[['True Labels', 'Stacking Preds', 'Stacking Probs']].to_excel(writer, 'Stacking Results')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualize predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's visualize the predicted probabilities from the ensembling approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT Probs</th>\n",
       "      <th>KNN Probs</th>\n",
       "      <th>LR Probs</th>\n",
       "      <th>RF Probs</th>\n",
       "      <th>True Lables</th>\n",
       "      <th>XGB Probs</th>\n",
       "      <th>LR_rank</th>\n",
       "      <th>DT_rank</th>\n",
       "      <th>KNN_rank</th>\n",
       "      <th>RF_rank</th>\n",
       "      <th>XGB_rank</th>\n",
       "      <th>Final_rank</th>\n",
       "      <th>Stacking Probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.478309</td>\n",
       "      <td>0.379190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084860</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.4750</td>\n",
       "      <td>0.413771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.472599</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569748</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.1625</td>\n",
       "      <td>0.501463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.714134</td>\n",
       "      <td>0.682558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768271</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.6500</td>\n",
       "      <td>0.646963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867841</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.738780</td>\n",
       "      <td>0.783630</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851906</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.9000</td>\n",
       "      <td>0.805147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>0.747650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954354</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.5250</td>\n",
       "      <td>0.829352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT Probs  KNN Probs  LR Probs  RF Probs  True Lables  XGB Probs  LR_rank  \\\n",
       "0  0.133333       0.44  0.478309  0.379190            1   0.084860     15.0   \n",
       "1  0.714286       0.92  0.472599  0.436441            0   0.569748     14.0   \n",
       "2  1.000000       0.64  0.714134  0.682558            0   0.768271     20.0   \n",
       "3  0.867841       0.68  0.738780  0.783630            1   0.851906     23.0   \n",
       "4  0.771739       0.68  0.750137  0.747650            1   0.954354     29.0   \n",
       "\n",
       "   DT_rank  KNN_rank  RF_rank  XGB_rank  Final_rank  Stacking Probs  \n",
       "0      2.0       1.0      5.0       3.0      9.4750        0.413771  \n",
       "1     18.5      48.0     11.0      15.0     14.1625        0.501463  \n",
       "2     50.0      11.0     18.0      26.0     22.6500        0.646963  \n",
       "3     41.0      20.0     42.5      33.0     28.9000        0.805147  \n",
       "4     26.0      20.0     22.5      44.0     33.5250        0.829352  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = probs_df\n",
    "temp['Stacking Probs'] = stacking_df.reset_index(drop=True)['Stacking Probs']\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = temp.sort_values(by='Stacking Probs', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAHVCAYAAACAOCDDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABa5v8HrK7HHjNuVQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1038c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "sns.regplot(temp.index.values, temp['Stacking Probs'].values, fit_reg=False, scatter_kws={\"s\": 10}, marker='s', label='Stacking')\n",
    "sns.regplot(temp.index.values, temp['LR Probs'].values, fit_reg=False, scatter_kws={\"s\": 15}, marker='o', label='LR')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can see here, the stacking predictions which yielded the best results is more consistent and smoother in terms of predictions. Achieving the sweet spot that balances bias and variance is a really difficult task and the combined error can only be mitagated to a certain extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. https://mlwave.com/kaggle-ensembling-guide/\n",
    "2. http://manish-m.com/?p=794\n",
    "3. http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
    "4. https://www.kaggle.com/general/20728"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
